#!/usr/bin/env python3
"""
Vocal Analyzer - Suno vocal stemsåˆ†æ

æ©Ÿèƒ½:
- ãƒ†ãƒ³ãƒæ¤œå‡º (BPM extraction)
- ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º (Verse/Chorus/Bridge)
- ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚«ãƒ¼ãƒ–æŠ½å‡º (Intensity mapping)
- Onset/Restæ¤œå‡º (æ—¢å­˜vocal_sync_fixedçµ±åˆ)

Usage:
    python scripts/vocal_analyzer.py <vocal_wav_path>
"""

import argparse
import json
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, Tuple

import numpy as np

try:
    import librosa
    import librosa.display
except ImportError:
    print("âš ï¸ librosa not installed. Run: pip install librosa")
    librosa = None

try:
    from utilities.vocal_sync_fixed import extract_onsets, find_long_rests
except ImportError:
    print("âš ï¸ vocal_sync_fixed not found")
    extract_onsets = None
    find_long_rests = None


@dataclass
class VocalSection:
    """ãƒœãƒ¼ã‚«ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±"""

    start_time: float  # é–‹å§‹æ™‚åˆ» (seconds)
    end_time: float  # çµ‚äº†æ™‚åˆ» (seconds)
    section_type: str  # verse, chorus, bridge, intro, outro
    energy_level: float  # 0.0-1.0
    peak_frequency: Optional[float] = None  # ãƒ”ãƒ¼ã‚¯å‘¨æ³¢æ•° (Hz)

    @property
    def duration(self) -> float:
        return self.end_time - self.start_time


@dataclass
class VocalAnalysis:
    """ãƒœãƒ¼ã‚«ãƒ«åˆ†æçµæœ"""

    wav_path: Path
    duration: float  # ç·æ™‚é–“ (seconds)
    tempo: float  # BPM
    tempo_confidence: float  # 0.0-1.0

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±
    sections: List[VocalSection] = field(default_factory=list)

    # ã‚¨ãƒãƒ«ã‚®ãƒ¼æƒ…å ±
    energy_curve: List[Tuple[float, float]] = field(default_factory=list)  # (time, energy)
    avg_energy: float = 0.0
    max_energy: float = 0.0

    # Onset/Restæƒ…å ± (vocal_sync_fixedçµ±åˆ)
    onsets: List[float] = field(default_factory=list)  # onsetæ™‚åˆ» (seconds)
    long_rests: List[Tuple[float, float]] = field(default_factory=list)  # (start, end)

    def to_dict(self) -> dict:
        """JSONå‡ºåŠ›ç”¨"""
        return {
            "wav_path": str(self.wav_path),
            "duration": self.duration,
            "tempo": self.tempo,
            "tempo_confidence": self.tempo_confidence,
            "sections": [
                {
                    "start_time": s.start_time,
                    "end_time": s.end_time,
                    "duration": s.duration,
                    "section_type": s.section_type,
                    "energy_level": s.energy_level,
                    "peak_frequency": s.peak_frequency,
                }
                for s in self.sections
            ],
            "energy_curve_samples": len(self.energy_curve),
            "avg_energy": self.avg_energy,
            "max_energy": self.max_energy,
            "onsets_count": len(self.onsets),
            "long_rests_count": len(self.long_rests),
        }


class VocalAnalyzer:
    """ãƒœãƒ¼ã‚«ãƒ«åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self):
        if not librosa:
            raise RuntimeError("librosa required. Install: pip install librosa")

    def analyze(self, wav_path: Path, verbose: bool = True) -> VocalAnalysis:
        """
        ãƒœãƒ¼ã‚«ãƒ«WAVåˆ†æ

        Args:
            wav_path: ãƒœãƒ¼ã‚«ãƒ«WAVãƒ•ã‚¡ã‚¤ãƒ«
            verbose: è©³ç´°å‡ºåŠ›

        Returns:
            VocalAnalysis
        """
        if not wav_path.exists():
            raise FileNotFoundError(f"Vocal WAV not found: {wav_path}")

        if verbose:
            print(f"ğŸ¤ Analyzing vocal: {wav_path.name}")

        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªèª­ã¿è¾¼ã¿
        y, sr = librosa.load(wav_path, sr=None)
        duration = librosa.get_duration(y=y, sr=sr)

        if verbose:
            print(f"  â±ï¸  Duration: {duration:.2f}s")
            print(f"  ğŸ”Š Sample rate: {sr} Hz")

        # ãƒ†ãƒ³ãƒæ¤œå‡º
        tempo, tempo_confidence = self._extract_tempo(y, sr, verbose)

        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚«ãƒ¼ãƒ–
        energy_curve, avg_energy, max_energy = self._extract_energy_curve(y, sr, verbose)

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º
        sections = self._detect_sections(y, sr, energy_curve, verbose)

        # Onsetæ¤œå‡º (vocal_sync_fixedçµ±åˆ)
        onsets = self._extract_onsets(wav_path, verbose)

        # Restæ¤œå‡º
        long_rests = self._extract_long_rests(wav_path, verbose)

        analysis = VocalAnalysis(
            wav_path=wav_path,
            duration=duration,
            tempo=tempo,
            tempo_confidence=tempo_confidence,
            sections=sections,
            energy_curve=energy_curve,
            avg_energy=avg_energy,
            max_energy=max_energy,
            onsets=onsets,
            long_rests=long_rests,
        )

        if verbose:
            print(f"\nâœ… Analysis complete!")
            print(f"   Tempo: {tempo:.1f} BPM (confidence: {tempo_confidence:.2f})")
            print(f"   Sections: {len(sections)}")
            print(f"   Avg Energy: {avg_energy:.3f}")
            print(f"   Onsets: {len(onsets)}")
            print(f"   Long Rests: {len(long_rests)}")

        return analysis

    def _extract_tempo(self, y: np.ndarray, sr: int, verbose: bool) -> Tuple[float, float]:
        """ãƒ†ãƒ³ãƒæ¤œå‡º"""
        if verbose:
            print("  ğŸµ Extracting tempo...")

        # librosaã®beat tracking
        onset_env = librosa.onset.onset_strength(y=y, sr=sr)
        tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)

        # Confidenceè¨ˆç®— (beatå¼·åº¦ã®æ¨™æº–åå·®)
        beat_strength = librosa.util.sync(onset_env, beats, aggregate=np.median)
        confidence = float(np.std(beat_strength) / (np.mean(beat_strength) + 1e-6))
        confidence = min(confidence, 1.0)

        return float(tempo), confidence

    def _extract_energy_curve(
        self, y: np.ndarray, sr: int, verbose: bool
    ) -> Tuple[List[Tuple[float, float]], float, float]:
        """ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚«ãƒ¼ãƒ–æŠ½å‡º"""
        if verbose:
            print("  ğŸ“Š Extracting energy curve...")

        # RMS energyè¨ˆç®— (ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚º: 0.1ç§’)
        frame_length = int(sr * 0.1)
        hop_length = frame_length // 2
        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]

        # æ™‚é–“è»¸
        times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)

        # (time, energy) ãƒšã‚¢
        energy_curve = [(float(t), float(e)) for t, e in zip(times, rms)]

        avg_energy = float(np.mean(rms))
        max_energy = float(np.max(rms))

        return energy_curve, avg_energy, max_energy

    def _detect_sections(
        self,
        y: np.ndarray,
        sr: int,
        energy_curve: List[Tuple[float, float]],
        verbose: bool,
    ) -> List[VocalSection]:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º (ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰åŒ–ãƒ™ãƒ¼ã‚¹)"""
        if verbose:
            print("  ğŸ¯ Detecting sections...")

        # ç°¡æ˜“å®Ÿè£…: ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¾å€¤ã§ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²
        sections = []
        energies = np.array([e for _, e in energy_curve])
        times = np.array([t for t, _ in energy_curve])

        # é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼ = Chorus, ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼ = Verse
        threshold = np.median(energies)

        in_section = False
        start_idx = 0
        current_type = "verse"

        for i, energy in enumerate(energies):
            is_high = energy > threshold

            if not in_section:
                if is_high or energy > 0.01:  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹
                    in_section = True
                    start_idx = i
                    current_type = "chorus" if is_high else "verse"
            else:
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å¤‰åŒ–æ¤œå‡º (ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒå¤§ããå¤‰åŒ–)
                if i > start_idx + 10:  # æœ€ä½1ç§’ã®é•·ã•
                    if (is_high and current_type == "verse") or (
                        not is_high and current_type == "chorus"
                    ):
                        # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                        sections.append(
                            VocalSection(
                                start_time=float(times[start_idx]),
                                end_time=float(times[i - 1]),
                                section_type=current_type,
                                energy_level=float(np.mean(energies[start_idx:i])),
                            )
                        )
                        # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹
                        start_idx = i
                        current_type = "chorus" if is_high else "verse"

        # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if in_section:
            sections.append(
                VocalSection(
                    start_time=float(times[start_idx]),
                    end_time=float(times[-1]),
                    section_type=current_type,
                    energy_level=float(np.mean(energies[start_idx:])),
                )
            )

        return sections

    def _extract_onsets(self, wav_path: Path, verbose: bool) -> List[float]:
        """OnsetæŠ½å‡º (vocal_sync_fixedçµ±åˆ)"""
        if not extract_onsets:
            return []

        if verbose:
            print("  ğŸ¶ Extracting onsets (vocal_sync_fixed)...")

        try:
            onsets = extract_onsets(str(wav_path))
            return onsets
        except Exception as e:
            if verbose:
                print(f"    âš ï¸ Onset extraction failed: {e}")
            return []

    def _extract_long_rests(self, wav_path: Path, verbose: bool) -> List[Tuple[float, float]]:
        """Long RestæŠ½å‡º (vocal_sync_fixedçµ±åˆ)"""
        if not find_long_rests:
            return []

        if verbose:
            print("  ğŸ”‡ Detecting long rests (vocal_sync_fixed)...")

        try:
            rests = find_long_rests(str(wav_path), min_duration=0.5)
            return rests
        except Exception as e:
            if verbose:
                print(f"    âš ï¸ Rest detection failed: {e}")
            return []


def main():
    parser = argparse.ArgumentParser(description="Analyze Suno vocal stem")
    parser.add_argument("wav_path", type=Path, help="Path to vocal WAV file")
    parser.add_argument(
        "--output",
        "-o",
        type=Path,
        default=Path("output/vocal_analysis.json"),
        help="Output JSON path",
    )

    args = parser.parse_args()

    # åˆ†æå®Ÿè¡Œ
    analyzer = VocalAnalyzer()
    analysis = analyzer.analyze(args.wav_path, verbose=True)

    # JSONå‡ºåŠ›
    args.output.parent.mkdir(parents=True, exist_ok=True)
    with open(args.output, "w", encoding="utf-8") as f:
        json.dump(analysis.to_dict(), f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“„ Analysis exported: {args.output}")
    print("=" * 70)
    print("ğŸ‰ Vocal analysis complete!")
    print("=" * 70)


if __name__ == "__main__":
    main()
