#!/usr/bin/env python3
"""
LAMDa Unified Database Builder for Vertex AI Colab Enterprise
==============================================================
å…¨LAMDaãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’çµ±åˆã—ãŸå®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:
- CHORDS_DATA (15GB): è©³ç´°MIDIã‚¤ãƒ™ãƒ³ãƒˆ â†’ ã‚³ãƒ¼ãƒ‰é€²è¡ŒæŠ½å‡º
- KILO_CHORDS_DATA (602MB): æ•´æ•°ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ â†’ é«˜é€Ÿæ¤œç´¢
- SIGNATURES_DATA (290MB): ç‰¹å¾´é‡ â†’ é¡ä¼¼åº¦ãƒãƒƒãƒãƒ³ã‚°
- TOTALS_MATRIX (33MB): çµ±è¨ˆãƒãƒˆãƒªãƒƒã‚¯ã‚¹ â†’ æ­£è¦åŒ–

å®Ÿè¡Œç’°å¢ƒ: Vertex AI Colab Enterprise
æ¨å¥¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹: e2-standard-4 (4 vCPU, 16GB RAM)
æ¨å®šå®Ÿè¡Œæ™‚é–“: 90-120åˆ† (å…¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†)
æ¨å®šã‚³ã‚¹ãƒˆ: Â¥30-50
"""

import sys
from pathlib import Path
import subprocess
import tarfile
import time

print("=" * 80)
print("LAMDa Unified Database Builder - Vertex AI Colab Enterprise")
print("å…¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’çµ±åˆå‡¦ç† (CHORDS + KILO + SIGNATURES + TOTALS)")
print("=" * 80)

# GCSè¨­å®š
BUCKET_NAME = "otobon"
LAMDA_GCS_PATH = "gs://otobon/lamda/"

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
WORK_DIR = Path("/home/jupyter/lamda_work")
WORK_DIR.mkdir(parents=True, exist_ok=True)

# ãƒªãƒã‚¸ãƒˆãƒªãƒ‘ã‚¹
REPO_PATH = WORK_DIR / "composer2-3"

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
DATA_DIR = WORK_DIR / "data" / "Los-Angeles-MIDI"
DATA_DIR.mkdir(parents=True, exist_ok=True)

# å‡ºåŠ›DBãƒ‘ã‚¹
DB_PATH = WORK_DIR / "lamda_unified.db"


def step1_clone_repo():
    """ã‚¹ãƒ†ãƒƒãƒ—1: ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³"""
    print("\n" + "=" * 80)
    print("[1/7] Cloning repository...")
    print("=" * 80)

    if REPO_PATH.exists():
        print(f"âœ… Repository already exists: {REPO_PATH}")
        print("   Pulling latest changes...")
        subprocess.run(["git", "-C", str(REPO_PATH), "pull"], check=True)
    else:
        print(f"ğŸ“¥ Cloning to {REPO_PATH}...")
        subprocess.run(
            [
                "git",
                "clone",
                "--depth",
                "1",
                "https://github.com/kinoshitayoshihiro/composer4.git",
                str(REPO_PATH),
            ],
            check=True,
        )

    print(f"âœ… Repository ready: {REPO_PATH}")


def step2_install_dependencies():
    """ã‚¹ãƒ†ãƒƒãƒ—2: ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
    print("\n" + "=" * 80)
    print("[2/7] Installing dependencies...")
    print("=" * 80)

    print("ğŸ“¦ Installing: music21, numpy, tqdm...")
    subprocess.run(["pip", "install", "-q", "music21", "numpy", "tqdm"], check=True)

    print("âœ… Dependencies installed")


def step3_download_chords_data():
    """ã‚¹ãƒ†ãƒƒãƒ—3: CHORDS_DATAãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    print("\n" + "=" * 80)
    print("[3/7] Downloading CHORDS_DATA (575MB compressed)...")
    print("=" * 80)

    tar_file = DATA_DIR / "CHORDS_DATA.tar.gz"

    if tar_file.exists():
        print(f"âœ… Already downloaded: {tar_file}")
    else:
        print(f"ğŸ“¥ Downloading from {LAMDA_GCS_PATH}CHORDS_DATA.tar.gz...")
        start = time.time()
        subprocess.run(
            ["gsutil", "cp", f"{LAMDA_GCS_PATH}CHORDS_DATA.tar.gz", str(tar_file)], check=True
        )
        elapsed = time.time() - start
        print(f"âœ… Downloaded in {elapsed:.1f}s")

    print(f"   Size: {tar_file.stat().st_size / 1024 / 1024:.1f} MB")

    # è§£å‡
    chords_dir = DATA_DIR / "CHORDS_DATA"
    if chords_dir.exists():
        print(f"âœ… Already extracted: {chords_dir}")
    else:
        print("ğŸ“¦ Extracting CHORDS_DATA...")
        start = time.time()
        with tarfile.open(tar_file, "r:gz") as tar:
            tar.extractall(DATA_DIR)
        elapsed = time.time() - start
        print(f"âœ… Extracted in {elapsed:.1f}s")


def step4_download_kilo_signatures():
    """ã‚¹ãƒ†ãƒƒãƒ—4: KILO_CHORDS_DATA + SIGNATURES_DATAãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    print("\n" + "=" * 80)
    print("[4/7] Downloading KILO_CHORDS_DATA (602MB) + SIGNATURES_DATA (290MB)...")
    print("=" * 80)

    # KILO_CHORDS_DATA
    kilo_dir = DATA_DIR / "KILO_CHORDS_DATA"
    if kilo_dir.exists():
        print(f"âœ… KILO_CHORDS_DATA already exists: {kilo_dir}")
    else:
        print("ğŸ“¥ Downloading KILO_CHORDS_DATA...")
        start = time.time()
        subprocess.run(
            ["gsutil", "-m", "cp", "-r", f"{LAMDA_GCS_PATH}KILO_CHORDS_DATA", str(DATA_DIR)],
            check=True,
        )
        elapsed = time.time() - start
        print(f"âœ… Downloaded in {elapsed:.1f}s")

    # SIGNATURES_DATA
    sig_dir = DATA_DIR / "SIGNATURES_DATA"
    if sig_dir.exists():
        print(f"âœ… SIGNATURES_DATA already exists: {sig_dir}")
    else:
        print("ğŸ“¥ Downloading SIGNATURES_DATA...")
        start = time.time()
        subprocess.run(
            ["gsutil", "-m", "cp", "-r", f"{LAMDA_GCS_PATH}SIGNATURES_DATA", str(DATA_DIR)],
            check=True,
        )
        elapsed = time.time() - start
        print(f"âœ… Downloaded in {elapsed:.1f}s")


def step5_download_totals():
    """ã‚¹ãƒ†ãƒƒãƒ—5: TOTALS_MATRIXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    print("\n" + "=" * 80)
    print("[5/7] Downloading TOTALS_MATRIX (33MB)...")
    print("=" * 80)

    totals_dir = DATA_DIR / "TOTALS_MATRIX"
    if totals_dir.exists():
        print(f"âœ… TOTALS_MATRIX already exists: {totals_dir}")
    else:
        print("ğŸ“¥ Downloading TOTALS_MATRIX...")
        start = time.time()
        subprocess.run(
            ["gsutil", "-m", "cp", "-r", f"{LAMDA_GCS_PATH}TOTALS_MATRIX", str(DATA_DIR)],
            check=True,
        )
        elapsed = time.time() - start
        print(f"âœ… Downloaded in {elapsed:.1f}s")


def step6_build_database():
    """ã‚¹ãƒ†ãƒƒãƒ—6: çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰"""
    print("\n" + "=" * 80)
    print("[6/7] Building unified database...")
    print("       Processing: CHORDS + KILO + SIGNATURES")
    print("=" * 80)

    # Python pathã«ãƒªãƒã‚¸ãƒˆãƒªã‚’è¿½åŠ 
    sys.path.insert(0, str(REPO_PATH))

    from lamda_unified_analyzer import LAMDaUnifiedAnalyzer

    print(f"ğŸ“Š Initializing LAMDaUnifiedAnalyzer...")
    print(f"   Data directory: {DATA_DIR}")
    print(f"   Output database: {DB_PATH}")

    analyzer = LAMDaUnifiedAnalyzer(DATA_DIR)

    start = time.time()
    analyzer.build_unified_database(DB_PATH)
    elapsed = time.time() - start

    print(f"\nâœ… Database built in {elapsed / 60:.1f} minutes")
    print(f"   Size: {DB_PATH.stat().st_size / 1024 / 1024:.1f} MB")


def step7_upload_database():
    """ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    print("\n" + "=" * 80)
    print("[7/7] Uploading database to GCS...")
    print("=" * 80)

    gcs_db_path = f"{LAMDA_GCS_PATH}lamda_unified.db"

    print(f"ğŸ“¤ Uploading to {gcs_db_path}...")
    start = time.time()
    subprocess.run(["gsutil", "cp", str(DB_PATH), gcs_db_path], check=True)
    elapsed = time.time() - start

    print(f"âœ… Uploaded in {elapsed:.1f}s")
    print(f"   GCS Path: {gcs_db_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    overall_start = time.time()

    try:
        step1_clone_repo()
        step2_install_dependencies()
        step3_download_chords_data()
        step4_download_kilo_signatures()
        step5_download_totals()
        step6_build_database()
        step7_upload_database()

        overall_elapsed = time.time() - overall_start

        print("\n" + "=" * 80)
        print("ğŸ‰ SUCCESS! LAMDa Unified Database Build Complete")
        print("=" * 80)
        print(f"â±ï¸  Total time: {overall_elapsed / 60:.1f} minutes")
        print(f"ğŸ’¾ Database: gs://otobon/lamda/lamda_unified.db")
        print(f"ğŸ“Š Size: {DB_PATH.stat().st_size / 1024 / 1024:.1f} MB")
        print("\nçµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™:")
        print("  â€¢ CHORDS_DATA ã‹ã‚‰ã‚³ãƒ¼ãƒ‰é€²è¡ŒæŠ½å‡º")
        print("  â€¢ KILO_CHORDS_DATA ã®æ•´æ•°ã‚·ãƒ¼ã‚±ãƒ³ã‚¹")
        print("  â€¢ SIGNATURES_DATA ã®æ¥½æ›²ç‰¹å¾´é‡")
        print("=" * 80)

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
