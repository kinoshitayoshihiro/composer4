# LAMDa Unified Database Build - Vertex AI Colab Enterprise Guide
# =================================================================
# çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã‚¬ã‚¤ãƒ‰ (CHORDS + KILO + SIGNATURES + TOTALS)
#
# å®Ÿè¡Œç’°å¢ƒ: Vertex AI Colab Enterprise
# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹: shimogami88-Default (e2-standard-4: 4 vCPU, 16GB RAM)
# ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: us-central1
# æ¨å®šå®Ÿè¡Œæ™‚é–“: 90-120åˆ†
# æ¨å®šã‚³ã‚¹ãƒˆ: Â¥30-50
#
# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆ:
# â€¢ CHORDS_DATA (15GB) â†’ ã‚³ãƒ¼ãƒ‰é€²è¡ŒæŠ½å‡º
# â€¢ KILO_CHORDS_DATA (602MB) â†’ æ•´æ•°ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
# â€¢ SIGNATURES_DATA (290MB) â†’ æ¥½æ›²ç‰¹å¾´é‡
# â€¢ TOTALS_MATRIX (33MB) â†’ çµ±è¨ˆãƒãƒˆãƒªãƒƒã‚¯ã‚¹

# ============================================================================
# Cell 1: ç’°å¢ƒç¢ºèªã¨èªè¨¼
# ============================================================================
import sys
from pathlib import Path
import subprocess
import time

print("=" * 80)
print("LAMDa Unified Database Builder")
print("çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ (CHORDS + KILO + SIGNATURES)")
print("=" * 80)
print(f"Python: {sys.version}")
print(f"Working directory: {Path.cwd()}")

# GCSèªè¨¼ç¢ºèª
print("\nğŸ“‹ Checking GCS access...")
result = subprocess.run(["gsutil", "ls", "gs://otobon/lamda/"], capture_output=True, text=True)
if result.returncode == 0:
    print("âœ… GCS access OK")
    print("   Files in gs://otobon/lamda/:")
    for line in result.stdout.strip().split("\n")[:10]:
        print(f"     {line}")
else:
    print("âŒ GCS access failed. Please authenticate:")
    print("   !gcloud auth application-default login")


# ============================================================================
# Cell 2: ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³ã¨ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# ============================================================================
print("\n" + "=" * 80)
print("[Step 1/7] Cloning repository and installing dependencies...")
print("=" * 80)

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
WORK_DIR = Path("/home/jupyter/lamda_unified_work")
WORK_DIR.mkdir(parents=True, exist_ok=True)

REPO_PATH = WORK_DIR / "composer2-3"

# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
if REPO_PATH.exists():
    print(f"âœ… Repository exists: {REPO_PATH}")
    subprocess.run(["git", "-C", str(REPO_PATH), "pull"], check=True)
else:
    print(f"ğŸ“¥ Cloning repository to {REPO_PATH}...")
    subprocess.run(
        [
            "git",
            "clone",
            "--depth",
            "1",
            "https://github.com/kinoshitayoshihiro/composer4.git",
            str(REPO_PATH),
        ],
        check=True,
    )

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
print("\nğŸ“¦ Installing dependencies...")
subprocess.run(["pip", "install", "-q", "music21", "numpy", "tqdm"], check=True)

print("âœ… Repository and dependencies ready")

# Python pathã«è¿½åŠ 
sys.path.insert(0, str(REPO_PATH))


# ============================================================================
# Cell 3: ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CHORDS_DATA)
# ============================================================================
print("\n" + "=" * 80)
print("[Step 2/7] Downloading CHORDS_DATA (575MB compressed â†’ 15GB extracted)")
print("=" * 80)

import tarfile

LAMDA_GCS_PATH = "gs://otobon/lamda/"
DATA_DIR = WORK_DIR / "data" / "Los-Angeles-MIDI"
DATA_DIR.mkdir(parents=True, exist_ok=True)

# CHORDS_DATA.tar.gzãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
tar_file = DATA_DIR / "CHORDS_DATA.tar.gz"

if tar_file.exists():
    print(f"âœ… Already downloaded: {tar_file}")
else:
    print(f"ğŸ“¥ Downloading from {LAMDA_GCS_PATH}CHORDS_DATA.tar.gz...")
    start = time.time()
    subprocess.run(
        ["gsutil", "cp", f"{LAMDA_GCS_PATH}CHORDS_DATA.tar.gz", str(tar_file)], check=True
    )
    elapsed = time.time() - start
    print(f"âœ… Downloaded in {elapsed:.1f}s ({tar_file.stat().st_size / 1024 / 1024:.1f} MB)")

# è§£å‡
chords_dir = DATA_DIR / "CHORDS_DATA"
if chords_dir.exists() and list(chords_dir.glob("*.pickle")):
    print(f"âœ… Already extracted: {chords_dir}")
    print(f"   Files: {len(list(chords_dir.glob('*.pickle')))} pickle files")
else:
    print("ğŸ“¦ Extracting CHORDS_DATA (this may take 5-10 minutes)...")
    start = time.time()
    with tarfile.open(tar_file, "r:gz") as tar:
        tar.extractall(DATA_DIR)
    elapsed = time.time() - start
    print(f"âœ… Extracted in {elapsed:.1f}s")
    print(f"   Files: {len(list(chords_dir.glob('*.pickle')))} pickle files")


# ============================================================================
# Cell 4: ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (KILO, SIGNATURES, TOTALS)
# ============================================================================
print("\n" + "=" * 80)
print("[Step 3/7] Downloading KILO_CHORDS (602MB) + SIGNATURES (290MB) + TOTALS (33MB)")
print("=" * 80)

# KILO_CHORDS_DATA
kilo_dir = DATA_DIR / "KILO_CHORDS_DATA"
if kilo_dir.exists():
    print(f"âœ… KILO_CHORDS_DATA exists: {kilo_dir}")
else:
    print("ğŸ“¥ Downloading KILO_CHORDS_DATA (602MB)...")
    start = time.time()
    subprocess.run(
        ["gsutil", "-m", "cp", "-r", f"{LAMDA_GCS_PATH}KILO_CHORDS_DATA", str(DATA_DIR)], check=True
    )
    elapsed = time.time() - start
    print(f"âœ… Downloaded in {elapsed:.1f}s")

# SIGNATURES_DATA
sig_dir = DATA_DIR / "SIGNATURES_DATA"
if sig_dir.exists():
    print(f"âœ… SIGNATURES_DATA exists: {sig_dir}")
else:
    print("ğŸ“¥ Downloading SIGNATURES_DATA (290MB)...")
    start = time.time()
    subprocess.run(
        ["gsutil", "-m", "cp", "-r", f"{LAMDA_GCS_PATH}SIGNATURES_DATA", str(DATA_DIR)], check=True
    )
    elapsed = time.time() - start
    print(f"âœ… Downloaded in {elapsed:.1f}s")

# TOTALS_MATRIX
totals_dir = DATA_DIR / "TOTALS_MATRIX"
if totals_dir.exists():
    print(f"âœ… TOTALS_MATRIX exists: {totals_dir}")
else:
    print("ğŸ“¥ Downloading TOTALS_MATRIX (33MB)...")
    start = time.time()
    subprocess.run(
        ["gsutil", "-m", "cp", "-r", f"{LAMDA_GCS_PATH}TOTALS_MATRIX", str(DATA_DIR)], check=True
    )
    elapsed = time.time() - start
    print(f"âœ… Downloaded in {elapsed:.1f}s")

print("\nâœ… All data sources ready:")
print(f"   â€¢ CHORDS_DATA: {len(list(chords_dir.glob('*.pickle')))} files")
print(f"   â€¢ KILO_CHORDS_DATA: {kilo_dir}")
print(f"   â€¢ SIGNATURES_DATA: {sig_dir}")
print(f"   â€¢ TOTALS_MATRIX: {totals_dir}")


# ============================================================================
# Cell 5: çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ (ãƒ¡ã‚¤ãƒ³å‡¦ç† - 60-90åˆ†)
# ============================================================================
print("\n" + "=" * 80)
print("[Step 4/7] Building unified database (estimated 60-90 minutes)")
print("=" * 80)

from lamda_unified_analyzer import LAMDaUnifiedAnalyzer

DB_PATH = WORK_DIR / "lamda_unified.db"

print(f"ğŸ“Š Initializing LAMDaUnifiedAnalyzer...")
print(f"   Data directory: {DATA_DIR}")
print(f"   Output database: {DB_PATH}")

analyzer = LAMDaUnifiedAnalyzer(DATA_DIR)

print("\nğŸ”¨ Starting database build...")
print("   This will process:")
print("   â€¢ CHORDS_DATA â†’ Extract chord progressions (longest step)")
print("   â€¢ KILO_CHORDS_DATA â†’ Store integer sequences")
print("   â€¢ SIGNATURES_DATA â†’ Store feature signatures")
print("   Progress bars will show detailed status...")

start = time.time()
analyzer.build_unified_database(DB_PATH)
elapsed = time.time() - start

print(f"\nâœ… Database built successfully in {elapsed / 60:.1f} minutes")
print(f"   Size: {DB_PATH.stat().st_size / 1024 / 1024:.1f} MB")


# ============================================================================
# Cell 6: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ============================================================================
print("\n" + "=" * 80)
print("[Step 5/7] Uploading database to GCS...")
print("=" * 80)

gcs_db_path = f"{LAMDA_GCS_PATH}lamda_unified.db"

print(f"ğŸ“¤ Uploading to {gcs_db_path}...")
start = time.time()
subprocess.run(["gsutil", "cp", str(DB_PATH), gcs_db_path], check=True)
elapsed = time.time() - start

print(f"âœ… Uploaded in {elapsed:.1f}s")
print(f"   GCS Path: {gcs_db_path}")


# ============================================================================
# Cell 7: å®Œäº†ã‚µãƒãƒªãƒ¼
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ‰ LAMDa Unified Database Build COMPLETE!")
print("=" * 80)

print("\nğŸ“Š Database Contents:")
print("   â€¢ Chord progressions from CHORDS_DATA")
print("   â€¢ Integer sequences from KILO_CHORDS_DATA")
print("   â€¢ Feature signatures from SIGNATURES_DATA")
print("")
print(f"ğŸ’¾ Database Location:")
print(f"   Local: {DB_PATH}")
print(f"   GCS: {gcs_db_path}")
print(f"   Size: {DB_PATH.stat().st_size / 1024 / 1024:.1f} MB")
print("")
print("ğŸ” Database Statistics:")

import sqlite3

conn = sqlite3.connect(DB_PATH)
cursor = conn.cursor()

cursor.execute("SELECT COUNT(*) FROM progressions")
prog_count = cursor.fetchone()[0]

cursor.execute("SELECT COUNT(*) FROM kilo_sequences")
kilo_count = cursor.fetchone()[0]

cursor.execute("SELECT COUNT(*) FROM signatures")
sig_count = cursor.fetchone()[0]

print(f"   â€¢ Total progressions: {prog_count:,}")
print(f"   â€¢ Total kilo sequences: {kilo_count:,}")
print(f"   â€¢ Total signatures: {sig_count:,}")

conn.close()

print("\n" + "=" * 80)
print("âœ… You can now download the database for local use:")
print(f"   gsutil cp {gcs_db_path} ./lamda_unified.db")
print("=" * 80)
